# Onyx Configuration - Cloud API Mode (No GPU Required)
# Copy of env.template with cloud API configurations

################################################################################
## COMMONLY MODIFIED CONFIGURATIONS
################################################################################
## Version of Onyx to deploy
IMAGE_TAG=latest

## Auth Settings
AUTH_TYPE=disabled
# For production, enable authentication:
# AUTH_TYPE=basic
# REQUIRE_EMAIL_VERIFICATION=true
# SMTP_SERVER=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USER=your-email@gmail.com
# SMTP_PASS=your-app-password

## Internet Search
# EXA_API_KEY=your-exa-api-key

## Base URL for redirects
WEB_DOMAIN=http://localhost:3000

## Enterprise Features
ENABLE_PAID_ENTERPRISE_EDITION_FEATURES=false

################################################################################
## SERVICES CONFIGURATIONS
################################################################################
## Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

## MinIO/S3 Configuration
S3_ENDPOINT_URL=http://minio:9000
S3_AWS_ACCESS_KEY_ID=minioadmin
S3_AWS_SECRET_ACCESS_KEY=minioadmin
S3_FILE_STORE_BUCKET_NAME=onyx-file-store-bucket
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

## Nginx Proxy Timeout Configuration (in seconds)
NGINX_PROXY_CONNECT_TIMEOUT=300
NGINX_PROXY_SEND_TIMEOUT=300
NGINX_PROXY_READ_TIMEOUT=300

################################################################################
## CLOUD API CONFIGURATION VIA METIS AI (NO GPU REQUIRED)
################################################################################
## Metis AI provides OpenAI-compatible API without VPN requirements
## Website: https://metisai.ir
## Docs: https://docs.metisai.ir

## IMPORTANT: Metis AI API Configuration
OPENAI_API_KEY=tpsg-ATDlOuvhdFEWjHUb4vHf56bU66LwoGi
OPENAI_API_BASE=https://api.metisai.ir/openai/v1

## Embedding Model Configuration (Using OpenAI via Metis)
DOCUMENT_ENCODER_MODEL=openai/text-embedding-3-small
DOC_EMBEDDING_DIM=1536
NORMALIZE_EMBEDDINGS=true

## Disable Local Model Server (Use Cloud APIs instead)
DISABLE_MODEL_SERVER=true

## Optional: Configure reranking with Cohere via Metis
# DEFAULT_CROSS_ENCODER_PROVIDER_TYPE=cohere
# DEFAULT_CROSS_ENCODER_API_KEY=tpsg-ATDlOuvhdFEWjHUb4vHf56bU66LwoGi
# Or use LiteLLM for reranking
# DEFAULT_CROSS_ENCODER_PROVIDER_TYPE=litellm

## Gen AI Settings (Configure via UI)
## After starting the app, go to Admin -> Settings -> LLM Providers
## Add a new provider with:
##   Provider: OpenAI
##   API Key: tpsg-ATDlOuvhdFEWjHUb4vHf56bU66LwoGi
##   API Base URL: https://api.metisai.ir/openai/v1
##   Model: gpt-4o (or any model from Metis)
##   Fast Model: gpt-4o-mini (or gpt-3.5-turbo)

################################################################################
## DEVELOPER, DEBUGGING, AND LOGGING
################################################################################
LOG_LEVEL=info
LOG_ALL_MODEL_INTERACTIONS=False
LOG_ONYX_MODEL_INTERACTIONS=False
LOG_INDIVIDUAL_MODEL_TOKENS=False

## Feature Flags
SHOW_EXTRA_CONNECTORS=false

################################################################################
## ADVANCED CONFIGURATIONS
################################################################################
## Pointer to services (Model servers disabled)
POSTGRES_HOST=relational_db
VESPA_HOST=index
REDIS_HOST=cache
INTERNAL_URL=http://api_server:8080

## Model Server hosts are not used when DISABLE_MODEL_SERVER=true
# MODEL_SERVER_HOST=
# INDEXING_MODEL_SERVER_HOST=
